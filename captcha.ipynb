{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd(),\"image_captcha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "path_image = glob.glob(os.path.join(path,\"*.png\"))\n",
    "def convert_image(im_path):\n",
    "    image = []\n",
    "    for im in range(len(im_path)):\n",
    "        img = Image.open(im_path[im])\n",
    "        img = img.resize((300,300))\n",
    "        img = np.asarray(img)\n",
    "        image.append(img)\n",
    "    print(\"Done\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "img = convert_image(path_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Thor\\\\Desktop\\\\yolo\\\\Deep-Learning-Coursera\\\\Convolutional Neural Networks\\\\Week3\\\\Car detection for Autonomous Driving\\\\image_captcha'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label\n",
    "path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_1 = os.path.join(os.getcwd(),\"label\")\n",
    "path_label = glob.glob(os.path.join(path_1,\"*.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def take_label(label_path):\n",
    "    label = []\n",
    "    for lab in range(len(label_path)):\n",
    "        with open(label_path[lab],\"r\") as f :\n",
    "            data = f.read()\n",
    "            label.append(data)\n",
    "    print(\"Done!\")\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "label = take_label(path_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAACRCAYAAADKOm81AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c380f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show some image\n",
    "fig,ax =  plt.subplots(1,3)\n",
    "ix = np.random.randint(0,7000,size = 3)\n",
    "for i in range(len(ix)):\n",
    "    ax[i].imshow(img[i],cmap=\"gray\")\n",
    "    ax[i].set_title(label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ayzz', 'oaax', 'dusr', 'jxlk', 'pjix']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocessing\n",
    "label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(string.ascii_lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_all = {ixd:label for label,ixd in enumerate(string.ascii_lowercase)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 26)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(0,num_classes=26).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_label_to_categical():\n",
    "    label_array = np.zeros((len(label),4,26))\n",
    "    for i_label in range(len(label)):\n",
    "        for index,ch in zip(range(len(label[i_label])),label[i_label]):   \n",
    "            label_array[i_label,index,:] = to_categorical(label_all[ch],num_classes=26)\n",
    "    print(\"Done!\")\n",
    "    return label_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "label_captcha = convert_label_to_categical()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_captcha = np.array(img)\n",
    "im_captcha = im_captcha.reshape((-1,1,300,300))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape  (7000, 1, 300, 300) label shape : (7000, 4, 26)\n"
     ]
    }
   ],
   "source": [
    "print(\"image shape \",im_captcha.shape,\"label shape :\",label_captcha.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(im_captcha,label_captcha,test_size =0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size : (4900, 1, 300, 300)\n",
      "test size : (4900, 4, 26)\n"
     ]
    }
   ],
   "source": [
    "print(\"train size :\",X_train.shape)\n",
    "print(\"test size :\",y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout,Conv2D,MaxPool2D,Activation,Dense,Flatten,Reshape,Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thor\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "model_input=Input((1,300,300))\n",
    "\n",
    "x = Conv2D(64,kernel_size=(3,3),strides=(1, 1),padding=\"same\")(model_input)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(128, kernel_size=(3,3),strides=(1, 1),padding=\"same\")(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "conv_out = Flatten()(x)\n",
    "\n",
    "x1 = Dense(26, activation='softmax')(conv_out)\n",
    "x2 = Dense(26, activation='softmax')(conv_out)\n",
    "x3 = Dense(26, activation='softmax')(conv_out)\n",
    "x4 = Dense(26, activation='softmax')(conv_out)\n",
    "\n",
    "\n",
    "lst = [x1, x2, x3, x4]\n",
    "\n",
    "model = Model(input=model_input, output=lst)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "optimizer='adam',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_4 (InputLayer)             (None, 1, 300, 300)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, 1, 300, 64)    172864      input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 1, 300, 64)    0           conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, 1, 300, 128)   73856       activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 1, 300, 128)   0           conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 1, 300, 128)   0           activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 38400)         0           dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 26)            998426      flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_13 (Dense)                 (None, 26)            998426      flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 26)            998426      flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_15 (Dense)                 (None, 26)            998426      flatten_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 4,240,424\n",
      "Trainable params: 4,240,424\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The model expects 4 target arrays, but only received one array. Found: array with shape (4900, 4, 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-1145d5f1892f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Thor\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m   1356\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1358\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1359\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Thor\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[0;32m   1236\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1238\u001b[1;33m                                     exception_prefix='target')\n\u001b[0m\u001b[0;32m   1239\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[0;32m   1240\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[1;32mC:\\Users\\Thor\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    105\u001b[0m                              \u001b[0mexception_prefix\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                              \u001b[1;34m' arrays, but only received one array. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m                              'Found: array with shape ' + str(data.shape))\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The model expects 4 target arrays, but only received one array. Found: array with shape (4900, 4, 26)"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=10,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26,)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_captcha[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_array = np.zeros((len(label),4,26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_array[1,1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
