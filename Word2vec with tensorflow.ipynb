{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_raw =\"He is the king . The king is royal . She is the royal  queen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert to lower case\n",
    "corpus_raw = corpus_raw.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for word in corpus_raw.split():\n",
    "    if word != \".\": # we need remove \".\"\n",
    "        words.append(word)\n",
    "words = set(words) # We create dictionary so remove duplicate word\n",
    "\n",
    "word2int = {}\n",
    "int2word = {}\n",
    "vocab_size = len(words)\n",
    "for i,word in enumerate(words):\n",
    "    word2int[word] = i\n",
    "    int2word[i] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word2int[\"king\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king\n"
     ]
    }
   ],
   "source": [
    "print(int2word[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw sentence as list \n",
    "raw_sentence = corpus_raw.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for sentence in raw_sentence:\n",
    "    sentences.append(sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['he', 'is', 'the', 'king'],\n",
       " ['the', 'king', 'is', 'royal'],\n",
       " ['she', 'is', 'the', 'royal', 'queen']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate training data\n",
    "data = []\n",
    "Window_size = 2\n",
    "for sentence in sentences :\n",
    "    for word_index,word in enumerate(sentence):\n",
    "        for nb_word in sentence[max(word_index - Window_size,0): min(word_index+ Window_size,len(sentence)) +1 ]:\n",
    "            if nb_word != word :\n",
    "                data.append([word,nb_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['he', 'is'],\n",
       " ['he', 'the'],\n",
       " ['is', 'he'],\n",
       " ['is', 'the'],\n",
       " ['is', 'king'],\n",
       " ['the', 'he'],\n",
       " ['the', 'is'],\n",
       " ['the', 'king'],\n",
       " ['king', 'is'],\n",
       " ['king', 'the'],\n",
       " ['the', 'king'],\n",
       " ['the', 'is'],\n",
       " ['king', 'the'],\n",
       " ['king', 'is'],\n",
       " ['king', 'royal'],\n",
       " ['is', 'the'],\n",
       " ['is', 'king'],\n",
       " ['is', 'royal'],\n",
       " ['royal', 'king'],\n",
       " ['royal', 'is'],\n",
       " ['she', 'is'],\n",
       " ['she', 'the'],\n",
       " ['is', 'she'],\n",
       " ['is', 'the'],\n",
       " ['is', 'royal'],\n",
       " ['the', 'she'],\n",
       " ['the', 'is'],\n",
       " ['the', 'royal'],\n",
       " ['the', 'queen'],\n",
       " ['royal', 'is'],\n",
       " ['royal', 'the'],\n",
       " ['royal', 'queen'],\n",
       " ['queen', 'the'],\n",
       " ['queen', 'royal']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to convert numbers to one hot vectors\n",
    "def to_one_hot(data_point_index, vocab_size):\n",
    "    temp = np.zeros(vocab_size)\n",
    "    temp[data_point_index] = 1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = [] # input word\n",
    "y_train = [] # output word\n",
    "for data_word in data:\n",
    "    x_train.append(to_one_hot(word2int[ data_word[0] ], vocab_size))\n",
    "    y_train.append(to_one_hot(word2int[ data_word[1] ], vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 7)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# placeholder\n",
    "X = tf.placeholder(tf.float32,[None,7])\n",
    "Y = tf.placeholder(tf.float32,[None,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable hiden 1\n",
    "W1 = tf.Variable(tf.random_normal([7,5]))\n",
    "b1 = tf.Variable(tf.constant(0.1,shape =[5]))\n",
    "hiden_1 = tf.matmul(X,W1) + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variable hiden 2\n",
    "W2 = tf.Variable(tf.random_normal([5,7]))\n",
    "b2 = tf.Variable(tf.constant(0.1,shape = [7]))\n",
    "hiden_2 = tf.matmul(hiden_1,W2) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = Y,logits=hiden_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initializer\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.235294\n",
      "1.7096\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for i in range(1000):\n",
    "    sess.run(optimizer,feed_dict={X:x_train,Y:y_train})\n",
    "predict = tf.equal(tf.arg_max(hiden_2,1),tf.arg_max(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(predict,tf.float32))\n",
    "print(sess.run(accuracy,feed_dict={X:x_train,Y:y_train}))\n",
    "print(sess.run(cross_entropy,feed_dict={X:x_train,Y:y_train}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01958227 -0.13184541 -0.90213287 -0.56716734  0.8208366 ]\n",
      " [ 0.87104267  1.35505605 -0.96144599 -0.37160841  0.8487801 ]\n",
      " [-0.25192827  0.27459705 -0.28976816  0.79217947  0.67895919]\n",
      " [-0.08619474  2.23241997  0.34758687  0.5944764   0.0489247 ]\n",
      " [ 0.72465742 -0.37924507  0.40199515 -0.76181579  0.17949352]\n",
      " [ 0.13059877 -0.72706902 -0.59972697 -0.21868251  0.29057246]\n",
      " [-0.47785416 -1.0059948  -0.23733111 -0.13084926  0.44342482]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(W1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = W1 + b1\n",
    "vector= sess.run(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TSNE(n_components=2,random_state=0)\n",
    "np.set_printoptions(suppress=True)\n",
    "vectors = model.fit_transform(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = Normalizer()\n",
    "vector_normal = normal.fit_transform(vectors,\"l2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is 0.22343425865\n",
      "queen 0.915279800966\n",
      "royal -0.459494161508\n",
      "he -0.151896011367\n",
      "king 0.976134338528\n",
      "the 0.994751378947\n",
      "she 0.162385963001\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAEVCAYAAACmMTGfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xdfb2358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig ,ax = plt.subplots()\n",
    "for word in words:\n",
    "    print(word, vector_normal[word2int[word]][1])\n",
    "    ax.annotate(word, (vector_normal[word2int[word]][0],vector_normal[word2int[word]][1] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
